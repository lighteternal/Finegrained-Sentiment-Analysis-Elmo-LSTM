{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analyzer (5-class). 0 = strongly negative, 1 = negative, 2 = neutral, 3 = positive 4 = strongly positive\n",
    "\n",
    "%cd /home/infili/translation/DimPapSandbox/realworldnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from allennlp.data.dataset_readers.stanford_sentiment_tree_bank import StanfordSentimentTreeBankDatasetReader\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "from examples.sentiment.sst_classifier import LstmClassifier\n",
    "from realworldnlp.predictors import SentenceClassifierPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8544it [00:01, 5528.64it/s]\n",
      "1101it [00:00, 1673.59it/s]\n",
      "100%|██████████| 9645/9645 [00:00<00:00, 442541.67it/s]\n",
      "accuracy: 0.3976, precision: 0.4757, recall: 0.2888, f1_measure: 0.3594, loss: 1.3558 ||: 100%|██████████| 267/267 [00:15<00:00, 16.98it/s]\n",
      "accuracy: 0.4432, precision: 0.5134, recall: 0.5818, f1_measure: 0.5455, loss: 1.2469 ||: 100%|██████████| 35/35 [00:01<00:00, 18.94it/s]\n",
      "accuracy: 0.4815, precision: 0.5830, recall: 0.4309, f1_measure: 0.4955, loss: 1.1936 ||: 100%|██████████| 267/267 [00:14<00:00, 17.94it/s]\n",
      "accuracy: 0.4714, precision: 0.5297, recall: 0.5939, f1_measure: 0.5600, loss: 1.2219 ||: 100%|██████████| 35/35 [00:01<00:00, 20.04it/s]\n",
      "accuracy: 0.5195, precision: 0.6356, recall: 0.4821, f1_measure: 0.5483, loss: 1.0983 ||: 100%|██████████| 267/267 [00:14<00:00, 18.39it/s]\n",
      "accuracy: 0.4886, precision: 0.6667, recall: 0.3273, f1_measure: 0.4390, loss: 1.2160 ||: 100%|██████████| 35/35 [00:01<00:00, 19.97it/s]\n",
      "accuracy: 0.5671, precision: 0.6593, recall: 0.5543, f1_measure: 0.6023, loss: 1.0019 ||: 100%|██████████| 267/267 [00:14<00:00, 18.27it/s]\n",
      "accuracy: 0.4741, precision: 0.5769, recall: 0.5455, f1_measure: 0.5607, loss: 1.2066 ||: 100%|██████████| 35/35 [00:01<00:00, 19.69it/s]\n",
      "accuracy: 0.6228, precision: 0.7054, recall: 0.6172, f1_measure: 0.6584, loss: 0.8994 ||: 100%|██████████| 267/267 [00:14<00:00, 18.00it/s]\n",
      "accuracy: 0.4823, precision: 0.5957, recall: 0.5091, f1_measure: 0.5490, loss: 1.2636 ||: 100%|██████████| 35/35 [00:01<00:00, 19.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 3,\n",
       " 'peak_cpu_memory_MB': 3687.732,\n",
       " 'peak_gpu_0_memory_MB': 3327,\n",
       " 'training_duration': '0:01:07.114216',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 3,\n",
       " 'epoch': 3,\n",
       " 'training_accuracy': 0.567064606741573,\n",
       " 'training_precision': 0.6592797636985779,\n",
       " 'training_recall': 0.554347813129425,\n",
       " 'training_f1_measure': 0.6022775173187256,\n",
       " 'training_loss': 1.0019111329696597,\n",
       " 'training_cpu_memory_MB': 3687.732,\n",
       " 'training_gpu_0_memory_MB': 3327,\n",
       " 'validation_accuracy': 0.47411444141689374,\n",
       " 'validation_precision': 0.5769230723381042,\n",
       " 'validation_recall': 0.5454545617103577,\n",
       " 'validation_f1_measure': 0.5607476830482483,\n",
       " 'validation_loss': 1.2065806065286908,\n",
       " 'best_validation_accuracy': 0.47411444141689374,\n",
       " 'best_validation_precision': 0.5769230723381042,\n",
       " 'best_validation_recall': 0.5454545617103577,\n",
       " 'best_validation_f1_measure': 0.5607476830482483,\n",
       " 'best_validation_loss': 1.2065806065286908}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model definition and training\n",
    "\n",
    "HIDDEN_DIM = 512\n",
    "CUDA_DEVICE = 0\n",
    "\n",
    "\n",
    "# In order to use ELMo, each word in a sentence needs to be indexed with\n",
    "# an array of character IDs.\n",
    "elmo_token_indexer = ELMoTokenCharactersIndexer()\n",
    "reader = StanfordSentimentTreeBankDatasetReader(\n",
    "    token_indexers={'tokens': elmo_token_indexer})\n",
    "\n",
    "train_dataset = reader.read('https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/train.txt')\n",
    "dev_dataset = reader.read('https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/dev.txt')\n",
    "\n",
    "# Initialize the ELMo-based token embedder using a pre-trained file.\n",
    "# This takes a while if you run this script for the first time\n",
    "\n",
    "# Original\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "# Medium\n",
    "# options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x2048_256_2048cnn_1xhighway/elmo_2x2048_256_2048cnn_1xhighway_options.json\"\n",
    "# weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x2048_256_2048cnn_1xhighway/elmo_2x2048_256_2048cnn_1xhighway_weights.hdf5\"\n",
    "\n",
    "# Use the 'Small' pre-trained model\n",
    "# options_file = ('https://s3-us-west-2.amazonaws.com/allennlp/models/elmo'\n",
    "#                '/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json')\n",
    "# weight_file = ('https://s3-us-west-2.amazonaws.com/allennlp/models/elmo'\n",
    "#               '/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5')\n",
    "\n",
    "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
    "\n",
    "vocab = Vocabulary.from_instances(train_dataset + dev_dataset,\n",
    "                                  min_count={'tokens': 3})\n",
    "\n",
    "# Pass in the ElmoTokenEmbedder instance instead\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})\n",
    "\n",
    "# The dimension of the ELMo embedding will be 2 x [size of LSTM hidden states]\n",
    "elmo_embedding_dim = 1024\n",
    "lstm = PytorchSeq2VecWrapper(\n",
    "    torch.nn.LSTM(elmo_embedding_dim, HIDDEN_DIM , batch_first=True))\n",
    "\n",
    "model = LstmClassifier(word_embeddings, lstm, vocab)\n",
    "optimizer = optim.AdamW(model.parameters())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "iterator = BucketIterator(batch_size=32, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  train_dataset=train_dataset,\n",
    "                  validation_dataset=dev_dataset,\n",
    "                  patience= 1,\n",
    "                  num_epochs=20,\n",
    "                  cuda_device= CUDA_DEVICE)\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model (change filename if needed)\n",
    "\n",
    "with open(\"/home/infili/translation/DimPapSandbox/sentiment_modelxx\", 'wb') as f:\n",
    "    torch.save(model.state_dict(), f)\n",
    "vocab.save_to_files(\"/home/infili/translation/DimPapSandbox/sentiment_vocabxx\")\n",
    "\n",
    "print(\"Model saved. DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/infili/translation/DimPapSandbox/realworldnlp\n",
      "LstmClassifier(\n",
      "  (embedder): BasicTextFieldEmbedder(\n",
      "    (token_embedder_tokens): ElmoTokenEmbedder(\n",
      "      (_elmo): Elmo(\n",
      "        (_elmo_lstm): _ElmoBiLm(\n",
      "          (_token_embedder): _ElmoCharacterEncoder(\n",
      "            (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "            (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
      "            (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
      "            (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
      "            (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
      "            (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
      "            (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
      "            (_highways): Highway(\n",
      "              (_layers): ModuleList(\n",
      "                (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "                (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (_elmo_lstm): ElmoLstm(\n",
      "            (forward_layer_0): LstmCellWithProjection(\n",
      "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "            )\n",
      "            (backward_layer_0): LstmCellWithProjection(\n",
      "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "            )\n",
      "            (forward_layer_1): LstmCellWithProjection(\n",
      "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "            )\n",
      "            (backward_layer_1): LstmCellWithProjection(\n",
      "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (_dropout): Dropout(p=0.5, inplace=False)\n",
      "        (scalar_mix_0): ScalarMix(\n",
      "          (scalar_parameters): ParameterList(\n",
      "              (0): Parameter containing: [torch.FloatTensor of size 1]\n",
      "              (1): Parameter containing: [torch.FloatTensor of size 1]\n",
      "              (2): Parameter containing: [torch.FloatTensor of size 1]\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): PytorchSeq2VecWrapper(\n",
      "    (_module): LSTM(1024, 512, batch_first=True)\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Reload pretrained model\n",
    "\n",
    "%cd /home/infili/translation/DimPapSandbox/realworldnlp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from allennlp.data.dataset_readers.stanford_sentiment_tree_bank import StanfordSentimentTreeBankDatasetReader\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "from examples.sentiment.sst_classifier import LstmClassifier\n",
    "from realworldnlp.predictors import SentenceClassifierPredictor\n",
    "\n",
    "HIDDEN_DIM = 512\n",
    "CUDA_DEVICE = 0\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "elmo_embedding_dim = 1024\n",
    "vocab = Vocabulary.from_files(\"/home/infili/translation/DimPapSandbox/sentiment_vocab1\")\n",
    "\n",
    "\n",
    "lstm = PytorchSeq2VecWrapper(\n",
    "    torch.nn.LSTM(elmo_embedding_dim, HIDDEN_DIM , batch_first=True))\n",
    "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})\n",
    "model = LstmClassifier(word_embeddings, lstm, vocab)\n",
    "\n",
    "# Reload the trained model.\n",
    "with open(\"/home/infili/translation/DimPapSandbox/sentiment_model1\", 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    model.eval()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Perform predictions\n",
    "\n",
    "elmo_token_indexer = ELMoTokenCharactersIndexer()\n",
    "reader = StanfordSentimentTreeBankDatasetReader(\n",
    "    token_indexers={'tokens': elmo_token_indexer})\n",
    "\n",
    "tokens = 'Great... another day of my life wasted to eat here.'\n",
    "predictor = SentenceClassifierPredictor(model, dataset_reader=reader)\n",
    "logits = predictor.predict(tokens)['logits']\n",
    "label_id = np.argmax(logits)\n",
    "\n",
    "print(model.vocab.get_token_from_index(label_id, 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
